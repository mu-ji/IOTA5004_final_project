{"cells":[{"cell_type":"markdown","metadata":{"id":"PeAJjK8aid1k"},"source":["## 1. Import libraies"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":731,"status":"ok","timestamp":1706686113341,"user":{"displayName":"YANG Siyuan","userId":"02843647817905742898"},"user_tz":-480},"id":"OK3APE1SicQF"},"outputs":[],"source":["import torch\n","from torch.autograd.functional import jacobian"]},{"cell_type":"markdown","metadata":{"id":"zyvJe-NdIwTE"},"source":["## 2. Jacobian matrix"]},{"cell_type":"markdown","metadata":{"id":"P-UZPjQVI2zM"},"source":["$\n","\\mathbf{a} = \\begin{bmatrix}\n","a_{1} & a_{2} & a_{3}\n","\\end{bmatrix}\n",",\n","\\mathbf{x} = \\begin{bmatrix}\n","x_{1} & x_{2} & x_{3}\n","\\end{bmatrix}\n",",\n","func = \\begin{bmatrix}\n","a_{1} * x_{1} & a_{2} * x_{2} & a_{3} * x_{3}\n","\\end{bmatrix}\n","=\n","\\begin{bmatrix}\n","y_{1} & y_{2} & y_{3}\n","\\end{bmatrix}\n","$"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1706686113341,"user":{"displayName":"YANG Siyuan","userId":"02843647817905742898"},"user_tz":-480},"id":"JWvuHunbhrht","outputId":"678b821c-cec9-47fd-9127-28838d98b9c1"},"outputs":[{"name":"stdout","output_type":"stream","text":["a = tensor([-0.6241,  0.5889, -1.4825])\n"]}],"source":["a = torch.randn(3)\n","print('a =', a)\n","def func(x):\n","    return a * x"]},{"cell_type":"markdown","metadata":{"id":"vZW1U1ZDMlE0"},"source":["$\n","\\left.\n","J =\n","\\left(\n","  \\begin{array}{ccc}\n","  \\frac{\\partial y_1}{\\partial x_1} & \\frac{\\partial y_1}{\\partial x_2} & \\frac{\\partial y_1}{\\partial x_3} \\\\\n","  \\frac{\\partial y_2}{\\partial x_1} & \\frac{\\partial y_2}{\\partial x_2} & \\frac{\\partial y_2}{\\partial x_3} \\\\\n","  \\frac{\\partial y_3}{\\partial x_1} & \\frac{\\partial y_3}{\\partial x_2} & \\frac{\\partial y_3}{\\partial x_3}\n","  \\end{array}\n","  \\right.\n","\\right)\n","$"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1706686113341,"user":{"displayName":"YANG Siyuan","userId":"02843647817905742898"},"user_tz":-480},"id":"HofvhyttKl9V","outputId":"34d0bd30-ea60-4532-919d-165d29f056e5"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","x = tensor([-0.2205, -0.3078, -0.8473])\n","\n","J = tensor([[-0.6241,  0.0000, -0.0000],\n","        [-0.0000,  0.5889, -0.0000],\n","        [-0.0000,  0.0000, -1.4825]])\n"]}],"source":["x = torch.randn(3)\n","print('\\nx =', x)\n","J = jacobian(func, x)\n","print('\\nJ =', J)"]},{"cell_type":"markdown","metadata":{"id":"_jMdcKCzJTT7"},"source":["## 3. Calculated gradient"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1706686113341,"user":{"displayName":"YANG Siyuan","userId":"02843647817905742898"},"user_tz":-480},"id":"p_Mmt5LRKt_E","outputId":"e35fdeed-ac85-4d40-8646-ddebb1f37cbb"},"outputs":[{"name":"stdout","output_type":"stream","text":["x = tensor([-0.9950,  0.1402, -0.3712], requires_grad=True)\n","\n","y = tensor([0.6210, 0.0825, 0.5503], grad_fn=<MulBackward0>)\n"]}],"source":["x = torch.randn(3, requires_grad=True)\n","print('x =', x)\n","y = func(x)\n","print('\\ny =', y)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1706686113341,"user":{"displayName":"YANG Siyuan","userId":"02843647817905742898"},"user_tz":-480},"id":"DiE4nrtrGqJu","outputId":"099ad180-90ee-4a72-f687-c44f24802588"},"outputs":[{"data":{"text/plain":["tensor([-0.6241,  0.5889, -1.4825])"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["# solution 1: backward()\n","# If y is a scalar, just y.backward()\n","# If not, need torch.ones_like(y), which equivalent to ∂L/∂y (L is equivalent to the uppermost, and backward mode generally assumes that the derivative of L is 1)\n","y.backward(torch.ones_like(y))\n","x.grad"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1706686113341,"user":{"displayName":"YANG Siyuan","userId":"02843647817905742898"},"user_tz":-480},"id":"OTFXU2kOGqY8","outputId":"8c831f2e-6642-433d-a7a3-3950bb523609"},"outputs":[{"data":{"text/plain":["tensor([-0.6241,  0.5889, -1.4825])"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["# solution 2: v.T @ J\n","# Instead of computing the Jacobian matrix itself, PyTorch allows you to compute Jacobian Product v.T\n","torch.ones_like(y) @ jacobian(func, x)   # torch.ones_like(y) equal to v.T"]},{"cell_type":"markdown","metadata":{"id":"H8ckC9EyLEo8"},"source":["## 4. use ```torch.autograd.grad()``` to get $u_x, u_{xx}$"]},{"cell_type":"markdown","metadata":{"id":"y33w_nmDaULG"},"source":["will use it in PINN"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1706686113341,"user":{"displayName":"YANG Siyuan","userId":"02843647817905742898"},"user_tz":-480},"id":"rE2FQtABJvik","outputId":"1961b366-2b07-450c-993f-5f4e19cf0bed"},"outputs":[{"name":"stdout","output_type":"stream","text":["u_x = tensor([[0.4811],\n","        [0.3443],\n","        [0.0684]], grad_fn=<MulBackward0>)\n","u_y = tensor([[1.],\n","        [1.],\n","        [1.]])\n","u_xx = tensor([[0.4811],\n","        [0.3443],\n","        [0.0684]], grad_fn=<MulBackward0>)\n"]}],"source":["def func(x, y):\n","    return x.exp() + y   # x.exp() + y**2\n","\n","a = torch.randn(3, 1, requires_grad=True)\n","b = torch.randn(3, 1, requires_grad=True)\n","u = func(a, b)\n","\n","u_x = torch.autograd.grad(u, a, grad_outputs=torch.ones_like(u),\n","                          retain_graph=True, create_graph=True)[0]\n","print('u_x =', u_x)\n","u_y = torch.autograd.grad(u, b, grad_outputs=torch.ones_like(u),\n","                          retain_graph=True, create_graph=True)[0]\n","print('u_y =', u_y)\n","\n","u_xx = torch.autograd.grad(u_x, a, grad_outputs=torch.ones_like(u_x),\n","                           retain_graph=True, create_graph=True)[0]\n","print('u_xx =', u_xx)\n","\n","# u_yy = torch.autograd.grad(u_y, b, grad_outputs=torch.ones_like(u_y),\n","#                            retain_graph=True, create_graph=True)[0]\n","# print('u_yy =', u_yy)\n"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1706686113341,"user":{"displayName":"YANG Siyuan","userId":"02843647817905742898"},"user_tz":-480},"id":"jcqo1lmyPQnc","outputId":"687e6d46-2397-4d69-dc90-e83d893d3f41"},"outputs":[{"name":"stdout","output_type":"stream","text":["<built-in method type of Tensor object at 0x000002684DDD0E90>\n","u_x = tensor([[ 0.1886],\n","        [-0.1228],\n","        [ 0.2779]], grad_fn=<MulBackward0>)\n","u_y = tensor([[0.1000],\n","        [0.1000],\n","        [0.1000]])\n"]},{"ename":"RuntimeError","evalue":"One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[1;32mIn[11], line 15\u001b[0m\n\u001b[0;32m     11\u001b[0m u_y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgrad(y, b, grad_outputs\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mones_like(u),\n\u001b[0;32m     12\u001b[0m                           retain_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, create_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mu_y =\u001b[39m\u001b[38;5;124m'\u001b[39m, u_y)\n\u001b[1;32m---> 15\u001b[0m u_xx \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mu_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mu_x\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mu_xx =\u001b[39m\u001b[38;5;124m'\u001b[39m, u_xx)\n\u001b[0;32m     19\u001b[0m u_yy \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgrad(u_y, b, grad_outputs\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mones_like(u_y),\n\u001b[0;32m     20\u001b[0m                            retain_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, create_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\n","File \u001b[1;32mc:\\Users\\11422\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\autograd\\__init__.py:394\u001b[0m, in \u001b[0;36mgrad\u001b[1;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched, materialize_grads)\u001b[0m\n\u001b[0;32m    390\u001b[0m     result \u001b[38;5;241m=\u001b[39m _vmap_internals\u001b[38;5;241m.\u001b[39m_vmap(vjp, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, allow_none_pass_through\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)(\n\u001b[0;32m    391\u001b[0m         grad_outputs_\n\u001b[0;32m    392\u001b[0m     )\n\u001b[0;32m    393\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 394\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    395\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    396\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_outputs_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    397\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    398\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    399\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    400\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    401\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    402\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    403\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m materialize_grads:\n\u001b[0;32m    404\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\n\u001b[0;32m    405\u001b[0m         output\n\u001b[0;32m    406\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m output \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    407\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mzeros_like(\u001b[38;5;28minput\u001b[39m, requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    408\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m (output, \u001b[38;5;28minput\u001b[39m) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(result, t_inputs)\n\u001b[0;32m    409\u001b[0m     )\n","\u001b[1;31mRuntimeError\u001b[0m: One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior."]}],"source":["def func(x, y):\n","    return 0.5*x*y, 0.1*y\n","\n","a = torch.randn(3, 1, requires_grad=True)\n","b = torch.randn(3, 1, requires_grad=True)\n","x,y = func(a, b)\n","print(x.type)\n","u_x = torch.autograd.grad(x, a, grad_outputs=torch.ones_like(u),\n","                          retain_graph=True, create_graph=True)[0]\n","print('u_x =', u_x)\n","u_y = torch.autograd.grad(y, b, grad_outputs=torch.ones_like(u),\n","                          retain_graph=True, create_graph=True)[0]\n","print('u_y =', u_y)\n","\n","u_xx = torch.autograd.grad(u_x, a, grad_outputs=torch.ones_like(u_x),\n","                           retain_graph=True, create_graph=True)[0]\n","print('u_xx =', u_xx)\n","\n","u_yy = torch.autograd.grad(u_y, b, grad_outputs=torch.ones_like(u_y),\n","                           retain_graph=True, create_graph=True)[0]\n","print('u_yy =', u_yy)\n","\n","u_xy = torch.autograd.grad(u_x, b, grad_outputs=torch.ones_like(u_x),\n","                           retain_graph=True, create_graph=True)[0]\n","print('u_xy =', u_xy)\n","\n","u_yx = torch.autograd.grad(u_y, a, grad_outputs=torch.ones_like(u_y),\n","                           retain_graph=True, create_graph=True)[0]\n","print('u_yx =', u_yx)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOhbEpQdq2b2rXhVXdGW1WR","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
